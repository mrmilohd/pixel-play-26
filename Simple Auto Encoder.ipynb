{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":126766,"databundleVersionId":15067517,"sourceType":"competition"},{"sourceId":14319694,"sourceType":"datasetVersion","datasetId":9141235}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"0aaf0011-337d-4691-8625-f3f2c50f9dc1","cell_type":"code","source":"# ============================================================\n# FLIP DETECTOR & DATASET CLEANER\n# Copy-paste these cells at the START of your Kaggle notebook\n# Run these BEFORE the anomaly detection code\n# ============================================================\n\n# ============================================================\n# CELL 1: Flip Detector Setup\n# ============================================================\n\nimport numpy as np\nimport os\nimport shutil\nfrom tqdm import tqdm\nimport random\nimport json\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torchvision.transforms.functional as TF\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Device: {device}\")\n\n# Paths\nTRAIN_PATH = '/kaggle/input/pixel-play-26/Avenue_Corrupted-20251221T112159Z-3-001/Avenue_Corrupted/Dataset/training_videos'\nTEST_PATH_ORIGINAL = '/kaggle/input/pixel-play-26/Avenue_Corrupted-20251221T112159Z-3-001/Avenue_Corrupted/Dataset/testing_videos'\nCLEAN_TEST_PATH = '/kaggle/working/cleaned_testing_videos'\n\n# Flip detector config\nFLIP_IMG_SIZE = 64\nFLIP_BATCH_SIZE = 64\nFLIP_EPOCHS = 5\nFLIP_LR = 0.001\n\nprint(f\"Train path exists: {os.path.exists(TRAIN_PATH)}\")\nprint(f\"Test path exists: {os.path.exists(TEST_PATH_ORIGINAL)}\")\n\n\n# ============================================================\n# CELL 2: Flip Detection Dataset\n# ============================================================\n\nclass FlipDetectionDataset(Dataset):\n    def __init__(self, video_path, img_size=64, samples_per_class=3000):\n        self.img_size = img_size\n        self.transform = transforms.Compose([\n            transforms.Resize((img_size, img_size)),\n            transforms.ToTensor(),\n        ])\n        \n        # Collect all frame paths\n        self.frame_paths = []\n        video_folders = [f for f in os.listdir(video_path) if os.path.isdir(os.path.join(video_path, f))]\n        for folder in video_folders:\n            folder_path = os.path.join(video_path, folder)\n            frames = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png'))]\n            for frame in frames:\n                self.frame_paths.append(os.path.join(folder_path, frame))\n        \n        print(f\"Total frames available: {len(self.frame_paths)}\")\n        \n        # Sample frames\n        if len(self.frame_paths) > samples_per_class:\n            selected = random.sample(self.frame_paths, samples_per_class)\n        else:\n            selected = self.frame_paths\n        \n        # Each frame: normal (0) and flipped (1)\n        self.samples = []\n        for path in selected:\n            self.samples.append((path, 0))\n            self.samples.append((path, 1))\n        random.shuffle(self.samples)\n        print(f\"Training samples: {len(self.samples)}\")\n    \n    def __len__(self):\n        return len(self.samples)\n    \n    def __getitem__(self, idx):\n        path, label = self.samples[idx]\n        img = Image.open(path).convert('L')\n        img_tensor = self.transform(img)\n        if label == 1:\n            img_tensor = TF.vflip(img_tensor)\n        return img_tensor, torch.tensor(label, dtype=torch.long)\n\nprint(\"Creating flip detection dataset...\")\nflip_dataset = FlipDetectionDataset(TRAIN_PATH, FLIP_IMG_SIZE, samples_per_class=3000)\nflip_loader = DataLoader(flip_dataset, batch_size=FLIP_BATCH_SIZE, shuffle=True, num_workers=2)\nprint(f\"Batches: {len(flip_loader)}\")\n\n\n# ============================================================\n# CELL 3: Flip Detector CNN Model\n# ============================================================\n\nclass FlipDetectorCNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n            nn.ReLU(),\n            nn.AdaptiveAvgPool2d(1),\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(64, 32),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(32, 2),\n        )\n    \n    def forward(self, x):\n        return self.classifier(self.features(x))\n\nflip_model = FlipDetectorCNN().to(device)\nprint(f\"Flip Detector: {sum(p.numel() for p in flip_model.parameters()):,} parameters\")\n\n\n# ============================================================\n# CELL 4: Train Flip Detector\n# ============================================================\n\nflip_criterion = nn.CrossEntropyLoss()\nflip_optimizer = optim.Adam(flip_model.parameters(), lr=FLIP_LR)\n\nprint(\"Training flip detector...\")\nflip_model.train()\n\nfor epoch in range(FLIP_EPOCHS):\n    total_loss = 0\n    correct = 0\n    total = 0\n    \n    pbar = tqdm(flip_loader, desc=f'Flip Detector Epoch {epoch+1}/{FLIP_EPOCHS}')\n    for images, labels in pbar:\n        images, labels = images.to(device), labels.to(device)\n        \n        outputs = flip_model(images)\n        loss = flip_criterion(outputs, labels)\n        \n        flip_optimizer.zero_grad()\n        loss.backward()\n        flip_optimizer.step()\n        \n        total_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n        \n        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100*correct/total:.1f}%'})\n    \n    print(f'Epoch {epoch+1}: Loss={total_loss/len(flip_loader):.4f}, Accuracy={100*correct/total:.1f}%')\n\ntorch.save(flip_model.state_dict(), 'flip_detector.pth')\nprint(\"Saved: flip_detector.pth\")\n\n\n# ============================================================\n# CELL 5: Scan Test Dataset for Flipped Frames\n# ============================================================\n\ndef detect_flipped_frames(model, test_path, img_size=64, threshold=0.5):\n    model.eval()\n    transform = transforms.Compose([\n        transforms.Resize((img_size, img_size)),\n        transforms.ToTensor(),\n    ])\n    \n    results = {}\n    flipped_count = 0\n    total_count = 0\n    \n    video_folders = sorted([f for f in os.listdir(test_path) if os.path.isdir(os.path.join(test_path, f))])\n    \n    with torch.no_grad():\n        for folder in tqdm(video_folders, desc='Scanning for flipped frames'):\n            folder_path = os.path.join(test_path, folder)\n            frames = sorted([f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png'))])\n            \n            results[folder] = {}\n            \n            for frame_name in frames:\n                frame_path = os.path.join(folder_path, frame_name)\n                img = Image.open(frame_path).convert('L')\n                img_tensor = transform(img).unsqueeze(0).to(device)\n                \n                output = model(img_tensor)\n                prob = torch.softmax(output, dim=1)\n                flip_prob = prob[0, 1].item()\n                \n                is_flipped = flip_prob > threshold\n                results[folder][frame_name] = {'is_flipped': is_flipped, 'flip_prob': flip_prob}\n                \n                if is_flipped:\n                    flipped_count += 1\n                total_count += 1\n    \n    print(f\"\\nScan Results:\")\n    print(f\"  Total frames: {total_count}\")\n    print(f\"  Flipped frames: {flipped_count} ({100*flipped_count/total_count:.1f}%)\")\n    \n    return results, flipped_count\n\nprint(\"\\nScanning test dataset...\")\nflip_results, num_flipped = detect_flipped_frames(flip_model, TEST_PATH_ORIGINAL, FLIP_IMG_SIZE)\n\n\n# ============================================================\n# CELL 6: Create Cleaned Test Dataset\n# ============================================================\n\ndef create_clean_dataset(test_path, clean_path, flip_results):\n    if os.path.exists(clean_path):\n        shutil.rmtree(clean_path)\n    os.makedirs(clean_path)\n    \n    corrected_count = 0\n    copied_count = 0\n    \n    for folder in tqdm(flip_results.keys(), desc='Creating clean dataset'):\n        src_folder = os.path.join(test_path, folder)\n        dst_folder = os.path.join(clean_path, folder)\n        os.makedirs(dst_folder, exist_ok=True)\n        \n        for frame_name, info in flip_results[folder].items():\n            src_path = os.path.join(src_folder, frame_name)\n            dst_path = os.path.join(dst_folder, frame_name)\n            \n            if info['is_flipped']:\n                img = Image.open(src_path)\n                img_corrected = TF.vflip(transforms.ToTensor()(img))\n                img_corrected = transforms.ToPILImage()(img_corrected)\n                img_corrected.save(dst_path)\n                corrected_count += 1\n            else:\n                shutil.copy2(src_path, dst_path)\n                copied_count += 1\n    \n    print(f\"\\nClean dataset created: {clean_path}\")\n    print(f\"  Corrected: {corrected_count}\")\n    print(f\"  Copied: {copied_count}\")\n    \n    return corrected_count, copied_count\n\nprint(\"\\nCreating cleaned dataset...\")\ncorrected, copied = create_clean_dataset(TEST_PATH_ORIGINAL, CLEAN_TEST_PATH, flip_results)\n\n\n# ============================================================\n# CELL 7: Visualize Results\n# ============================================================\n\n# Get list of flipped frames\nflipped_frames = []\nfor folder, frames in flip_results.items():\n    for frame_name, info in frames.items():\n        if info['is_flipped']:\n            flipped_frames.append((folder, frame_name, info['flip_prob']))\n\nflipped_frames.sort(key=lambda x: x[2], reverse=True)\n\nprint(f\"\\nTop 10 flipped frames:\")\nfor folder, frame, prob in flipped_frames[:10]:\n    print(f\"  {folder}/{frame}: {prob:.4f}\")\n\n# Visualize\nif len(flipped_frames) > 0:\n    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n    \n    for i in range(min(5, len(flipped_frames))):\n        folder, frame_name, prob = flipped_frames[i]\n        \n        # Original\n        orig_path = os.path.join(TEST_PATH_ORIGINAL, folder, frame_name)\n        orig_img = Image.open(orig_path).convert('L')\n        axes[0, i].imshow(orig_img, cmap='gray')\n        axes[0, i].set_title(f'Original\\nP={prob:.2f}')\n        axes[0, i].axis('off')\n        \n        # Cleaned\n        clean_path = os.path.join(CLEAN_TEST_PATH, folder, frame_name)\n        clean_img = Image.open(clean_path).convert('L')\n        axes[1, i].imshow(clean_img, cmap='gray')\n        axes[1, i].set_title('Corrected')\n        axes[1, i].axis('off')\n    \n    plt.suptitle('Original vs Corrected Frames', fontsize=14)\n    plt.tight_layout()\n    plt.savefig('flip_correction_comparison.png', dpi=150)\n    plt.show()\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"FLIP DETECTION COMPLETE!\")\nprint(\"=\"*60)\nprint(f\"Flipped frames detected: {num_flipped}\")\nprint(f\"Cleaned dataset: {CLEAN_TEST_PATH}\")\nprint(\"=\"*60)\n\n\n# ============================================================\n# CELL 8: UPDATE TEST_PATH FOR ANOMALY DETECTION\n# ============================================================\n\n# IMPORTANT: This sets TEST_PATH to use the cleaned dataset\n# The anomaly detection code below will use this path\n\nTEST_PATH = CLEAN_TEST_PATH\nprint(f\"\\n*** TEST_PATH is now set to: {TEST_PATH} ***\")\nprint(\"Anomaly detection will use the CLEANED dataset!\\n\")\n\n\n# ============================================================\n# NOW CONTINUE WITH YOUR ANOMALY DETECTION CODE BELOW\n# (from pixelplay_v2_fixed.ipynb)\n# \n# The TEST_PATH variable is already set to the cleaned dataset\n# ============================================================","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:26:43.380805Z","iopub.execute_input":"2026-01-07T06:26:43.381515Z","iopub.status.idle":"2026-01-07T06:26:44.740533Z","shell.execute_reply.started":"2026-01-07T06:26:43.381480Z","shell.execute_reply":"2026-01-07T06:26:44.733860Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nTrain path exists: True\nTest path exists: True\nCreating flip detection dataset...\nTotal frames available: 9204\nTraining samples: 6000\nBatches: 94\nFlip Detector: 25,442 parameters\nTraining flip detector...\n","output_type":"stream"},{"name":"stderr","text":"Flip Detector Epoch 1/5:  11%|█         | 10/94 [00:01<00:10,  7.82it/s, loss=0.6912, acc=48.3%]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1684249655.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflip_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Flip Detector Epoch {epoch+1}/{FLIP_EPOCHS}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1454\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1455\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":15},{"id":"4c78d216-e9cc-4218-aa0e-6936c33f59be","cell_type":"markdown","source":"# Pixel Play'26: Fully Configurable Anomaly Detection\n\n## Features:\n- **Configurable data augmentation** (normal/noisy/flipped percentages)\n- **Configurable temporal length** (1 to 20+ frames per cuboid)\n- **Configurable stride/sliding window**\n- **Load pretrained model** option\n- **Auto-zip all outputs**\n\n## Note:\n- `TEMPORAL_LENGTH = 1`: Single-frame autoencoder (no temporal info)\n- `TEMPORAL_LENGTH > 1`: Temporal cuboid autoencoder (captures motion)","metadata":{}},{"id":"d6be667e-6ae1-48b6-b3a1-6234beb635d2","cell_type":"markdown","source":"---\n## 1. CONFIGURATION\n---","metadata":{}},{"id":"a0f537b7-1366-42cc-bcb0-23ce5b51e963","cell_type":"code","source":"# ╔════════════════════════════════════════════════════════════════╗\n# ║                    CONFIGURATION                               ║\n# ╚════════════════════════════════════════════════════════════════╝\n\n# ============== DATA AUGMENTATION ==============\nNORMAL_PERCENT =60     # % of normal frames (must sum to 100)\nNOISY_PERCENT = 40      # % of noisy frames\nFLIPPED_PERCENT = 0    # % of flipped frames\nNOISE_FACTOR = 0.1373     # Noise intensity (0.1=light, 0.3=heavy)\n\n# ============== TEMPORAL SETTINGS ==============\nTEMPORAL_LENGTH = 16  # Frames per cuboid (1 = single frame, 10 = temporal)\nSTRIDE = 2               # Sliding window stride\n# ============== TRAINING ==============\nIMG_SIZE = 128\nBATCH_SIZE = 32\nEPOCHS = 25\nLEARNING_RATE = 0.001\nWEIGHT_DECAY = 1e-4\n\n# ============== PRETRAINED MODEL ==============\nLOAD_PRETRAINED = False\nPRETRAINED_PATH = '/kaggle/input/128dataset/trained_model.pth'\n\n# ============== OUTPUT ==============\nOUTPUT_ZIP_NAME = 'output_results.zip'\nMODEL_SAVE_NAME = 'trained_model.pth'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:26:51.183797Z","iopub.execute_input":"2026-01-07T06:26:51.184301Z","iopub.status.idle":"2026-01-07T06:26:51.189685Z","shell.execute_reply.started":"2026-01-07T06:26:51.184268Z","shell.execute_reply":"2026-01-07T06:26:51.188984Z"}},"outputs":[],"execution_count":16},{"id":"987bd48a-9256-4411-b659-fc9a7c851376","cell_type":"code","source":"# Validate\nassert NORMAL_PERCENT + NOISY_PERCENT + FLIPPED_PERCENT == 100, \"Percentages must sum to 100!\"\nassert TEMPORAL_LENGTH >= 1, \"TEMPORAL_LENGTH must be >= 1\"\nassert STRIDE >= 1, \"STRIDE must be >= 1\"\n\nprint(\"=\"*50)\nprint(\"CONFIGURATION\")\nprint(\"=\"*50)\nprint(f\"Augmentation: {NORMAL_PERCENT}% normal, {NOISY_PERCENT}% noisy, {FLIPPED_PERCENT}% flipped\")\nprint(f\"Temporal: {TEMPORAL_LENGTH} frames, Stride: {STRIDE}\")\nprint(f\"Training: {EPOCHS} epochs, LR: {LEARNING_RATE}\")\nprint(f\"Pretrained: {LOAD_PRETRAINED}\")\nif TEMPORAL_LENGTH == 1:\n    print(\"\\n⚠️  TEMPORAL_LENGTH=1: Single-frame mode (no temporal info)\")\nprint(\"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:26:51.190989Z","iopub.execute_input":"2026-01-07T06:26:51.191183Z","iopub.status.idle":"2026-01-07T06:26:51.205260Z","shell.execute_reply.started":"2026-01-07T06:26:51.191159Z","shell.execute_reply":"2026-01-07T06:26:51.204604Z"}},"outputs":[{"name":"stdout","text":"==================================================\nCONFIGURATION\n==================================================\nAugmentation: 60% normal, 40% noisy, 0% flipped\nTemporal: 16 frames, Stride: 2\nTraining: 25 epochs, LR: 0.001\nPretrained: False\n==================================================\n","output_type":"stream"}],"execution_count":17},{"id":"0726c625-4eb4-47c8-939a-bba6f448ea88","cell_type":"markdown","source":"---\n## 2. Setup\n---","metadata":{}},{"id":"e20d82d4-b9cf-4c0f-9cca-9518d401df09","cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport random\nimport zipfile\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torchvision.transforms.functional as TF\n\nSEED = 42\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nrandom.seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(SEED)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:26:51.206013Z","iopub.execute_input":"2026-01-07T06:26:51.206213Z","iopub.status.idle":"2026-01-07T06:26:51.220670Z","shell.execute_reply.started":"2026-01-07T06:26:51.206196Z","shell.execute_reply":"2026-01-07T06:26:51.220105Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":18},{"id":"e90d39a7-cc06-4907-bcd1-ed389b97c29e","cell_type":"code","source":"TRAIN_PATH = '/kaggle/input/pixel-play-26/Avenue_Corrupted-20251221T112159Z-3-001/Avenue_Corrupted/Dataset/training_videos'\nTEST_PATH = '/kaggle/working/cleaned_testing_videos'\nprint(f\"Train path exists: {os.path.exists(TRAIN_PATH)}\")\nprint(f\"Test path exists: {os.path.exists(TEST_PATH)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:26:51.221549Z","iopub.execute_input":"2026-01-07T06:26:51.221879Z","iopub.status.idle":"2026-01-07T06:26:51.233469Z","shell.execute_reply.started":"2026-01-07T06:26:51.221849Z","shell.execute_reply":"2026-01-07T06:26:51.232938Z"}},"outputs":[{"name":"stdout","text":"Train path exists: True\nTest path exists: True\n","output_type":"stream"}],"execution_count":19},{"id":"d06eed86-6e20-4820-9902-1a651ad3ddc9","cell_type":"markdown","source":"---\n## 3. Augmentation\n---","metadata":{}},{"id":"f87fe769-f249-48d4-ac32-4f46874eb9f5","cell_type":"code","source":"def add_gaussian_noise(tensor, noise_factor=0.1373):\n    \"\"\"\n    tensor: input in [0,1], shape (B,1,H,W) or (B,C,H,W)\n    noise_factor: max deviation in normalized units\n                  (35 / 255 ≈ 0.1373)\n    \"\"\"\n    noise = torch.empty_like(tensor).uniform_(-noise_factor, noise_factor)\n    return torch.clamp(tensor + noise, 0.0, 1.0)\n\n\ndef vertical_flip(tensor):\n    return TF.vflip(tensor)\n\ndef apply_augmentation(tensor, aug_type, noise_factor=0.2):\n    if aug_type == 'normal':\n        return tensor\n    elif aug_type == 'noisy':\n        return add_gaussian_noise(tensor, noise_factor)\n    elif aug_type == 'flipped':\n        return vertical_flip(tensor)\n    else:\n        return tensor\n\nprint(\"Augmentation functions ready!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:26:51.234926Z","iopub.execute_input":"2026-01-07T06:26:51.235139Z","iopub.status.idle":"2026-01-07T06:26:51.245331Z","shell.execute_reply.started":"2026-01-07T06:26:51.235121Z","shell.execute_reply":"2026-01-07T06:26:51.244820Z"}},"outputs":[{"name":"stdout","text":"Augmentation functions ready!\n","output_type":"stream"}],"execution_count":20},{"id":"b98e4c5c-20cd-4789-bb47-8b302e30937b","cell_type":"markdown","source":"---\n## 4. Dataset\n---","metadata":{}},{"id":"154a9551-e094-42fb-8edb-fcbc6c75009a","cell_type":"code","source":"class AugmentedVideoDataset(Dataset):\n    def __init__(self, video_path, temporal_length=10, stride=1, img_size=128,\n                 normal_percent=50, noisy_percent=25, flipped_percent=25,\n                 noise_factor=0.2, is_test=False):\n        self.video_path = video_path\n        self.temporal_length = temporal_length\n        self.stride = stride\n        self.img_size = img_size\n        self.noise_factor = noise_factor\n        self.is_test = is_test\n        self.normal_percent = normal_percent\n        self.noisy_percent = noisy_percent\n        \n        self.transform = transforms.Compose([\n            transforms.Resize((img_size, img_size)),\n            transforms.ToTensor()\n        ])\n        \n        self.samples = []\n        self._prepare_samples()\n    \n    def _prepare_samples(self):\n        video_folders = sorted([f for f in os.listdir(self.video_path)\n                               if os.path.isdir(os.path.join(self.video_path, f))])\n        \n        all_cuboids = []\n        for folder in video_folders:\n            folder_path = os.path.join(self.video_path, folder)\n            frames = sorted([f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png'))])\n            max_start = len(frames) - self.temporal_length\n            for start_idx in range(0, max_start + 1, self.stride):\n                all_cuboids.append((folder, start_idx))\n        \n        if self.is_test:\n            self.samples = [(f, i, 'normal') for f, i in all_cuboids]\n        else:\n            random.shuffle(all_cuboids)\n            total = len(all_cuboids)\n            normal_count = int(total * self.normal_percent / 100)\n            noisy_count = int(total * self.noisy_percent / 100)\n            \n            for i, (folder, idx) in enumerate(all_cuboids):\n                if i < normal_count:\n                    aug = 'normal'\n                elif i < normal_count + noisy_count:\n                    aug = 'noisy'\n                else:\n                    aug = 'flipped'\n                self.samples.append((folder, idx, aug))\n            random.shuffle(self.samples)\n        \n        print(f\"Dataset: {len(self.samples)} samples (T={self.temporal_length}, stride={self.stride})\")\n    \n    def __len__(self):\n        return len(self.samples)\n    \n    def __getitem__(self, idx):\n        folder, start_idx, aug_type = self.samples[idx]\n        folder_path = os.path.join(self.video_path, folder)\n        frames = sorted([f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png'))])\n        \n        cuboid = []\n        for i in range(self.temporal_length):\n            img = Image.open(os.path.join(folder_path, frames[start_idx + i])).convert('L')\n            img_tensor = self.transform(img)\n            img_tensor = apply_augmentation(img_tensor, aug_type, self.noise_factor)\n            cuboid.append(img_tensor)\n        \n        return torch.cat(cuboid, dim=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:26:51.818872Z","iopub.execute_input":"2026-01-07T06:26:51.819131Z","iopub.status.idle":"2026-01-07T06:26:51.830210Z","shell.execute_reply.started":"2026-01-07T06:26:51.819108Z","shell.execute_reply":"2026-01-07T06:26:51.829508Z"}},"outputs":[],"execution_count":22},{"id":"c1db4f36-08fe-4c3e-b271-edf4c310818d","cell_type":"code","source":"print(\"Creating training dataset...\")\ntrain_dataset = AugmentedVideoDataset(\n    TRAIN_PATH, TEMPORAL_LENGTH, STRIDE, IMG_SIZE,\n    NORMAL_PERCENT, NOISY_PERCENT, FLIPPED_PERCENT, NOISE_FACTOR, is_test=False\n)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\nprint(f\"Batches: {len(train_loader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:26:51.831199Z","iopub.execute_input":"2026-01-07T06:26:51.831456Z","iopub.status.idle":"2026-01-07T06:26:51.866914Z","shell.execute_reply.started":"2026-01-07T06:26:51.831436Z","shell.execute_reply":"2026-01-07T06:26:51.866405Z"}},"outputs":[{"name":"stdout","text":"Creating training dataset...\nDataset: 4486 samples (T=16, stride=2)\nBatches: 141\n","output_type":"stream"}],"execution_count":23},{"id":"de96eaf9-2809-45df-8bf2-920ec31da4a9","cell_type":"markdown","source":"---\n## 5. Model\n---","metadata":{}},{"id":"780db41d-516b-4ca5-a0d0-5a76f93f8b53","cell_type":"code","source":"class ConvAutoencoder(nn.Module):\n    def __init__(self, temporal_length=10):\n        super().__init__()\n        self.temporal_length = temporal_length\n        \n        self.encoder = nn.Sequential(\n            nn.Conv2d(temporal_length, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(True), nn.Dropout2d(0.2),\n            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(True), nn.Dropout2d(0.2),\n            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(True), nn.Dropout2d(0.2),\n            nn.Conv2d(256, 512, 4, 2, 1), nn.BatchNorm2d(512), nn.ReLU(True),  # No dropout on last\n        )\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(512, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(True),\n            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(True),\n            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(True),\n            nn.ConvTranspose2d(64, temporal_length, 4, 2, 1), nn.Sigmoid(),\n        )\n    \n    def forward(self, x):\n        return self.decoder(self.encoder(x))\n\nmodel = ConvAutoencoder(TEMPORAL_LENGTH).to(device)\nprint(f\"Model: {sum(p.numel() for p in model.parameters()):,} parameters\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:26:51.867668Z","iopub.execute_input":"2026-01-07T06:26:51.867884Z","iopub.status.idle":"2026-01-07T06:26:51.918484Z","shell.execute_reply.started":"2026-01-07T06:26:51.867865Z","shell.execute_reply":"2026-01-07T06:26:51.917889Z"}},"outputs":[{"name":"stdout","text":"Model: 5,542,032 parameters\n","output_type":"stream"}],"execution_count":24},{"id":"6d4d78bf-b7fa-4b42-bfca-4e84f286d8be","cell_type":"code","source":"if LOAD_PRETRAINED and os.path.exists(PRETRAINED_PATH):\n    model.load_state_dict(torch.load(PRETRAINED_PATH, map_location=device))\n    print(f\"Loaded pretrained model: {PRETRAINED_PATH}\")\nelif LOAD_PRETRAINED:\n    print(f\"WARNING: {PRETRAINED_PATH} not found, training from scratch\")\n    LOAD_PRETRAINED = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:26:51.919155Z","iopub.execute_input":"2026-01-07T06:26:51.919339Z","iopub.status.idle":"2026-01-07T06:26:51.923260Z","shell.execute_reply.started":"2026-01-07T06:26:51.919322Z","shell.execute_reply":"2026-01-07T06:26:51.922676Z"}},"outputs":[],"execution_count":25},{"id":"afc40072-6da4-460f-af4a-090ea8301134","cell_type":"markdown","source":"---\n## 6. Training\n---","metadata":{}},{"id":"1c2b9de9-642e-4bbd-a7e7-14ec3cc7ed08","cell_type":"code","source":"criterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n\ndef train_model(model, loader, criterion, optimizer, epochs):\n    model.train()\n    history = []\n    for epoch in range(epochs):\n        total_loss = 0\n        for batch in tqdm(loader, desc=f'Epoch {epoch+1}/{epochs}'):\n            batch = batch.to(device)\n            output = model(batch)\n            loss = criterion(output, batch)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        avg_loss = total_loss / len(loader)\n        history.append(avg_loss)\n        print(f'Epoch {epoch+1}: Loss = {avg_loss:.6f}')\n    return history","metadata":{"execution":{"iopub.status.busy":"2026-01-07T06:26:51.926121Z","iopub.execute_input":"2026-01-07T06:26:51.926495Z","iopub.status.idle":"2026-01-07T06:26:51.935000Z","shell.execute_reply.started":"2026-01-07T06:26:51.926427Z","shell.execute_reply":"2026-01-07T06:26:51.934228Z"},"trusted":true},"outputs":[],"execution_count":26},{"id":"1454d921-b170-4bbc-ab96-74b2686a39f3","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4a5919e7-93c2-40cf-a6e7-242aa4b82513","cell_type":"code","source":"if not LOAD_PRETRAINED:\n    print(f\"\\nTraining with T={TEMPORAL_LENGTH}, Stride={STRIDE}\")\n    history = train_model(model, train_loader, criterion, optimizer, EPOCHS)\n    torch.save(model.state_dict(), MODEL_SAVE_NAME)\n    print(f\"Model saved: {MODEL_SAVE_NAME}\")\n    \n    plt.figure(figsize=(10, 5))\n    plt.plot(history, 'b-', linewidth=2)\n    plt.xlabel('Epoch'); plt.ylabel('Loss')\n    plt.title(f'Training Loss (T={TEMPORAL_LENGTH}, Stride={STRIDE})')\n    plt.grid(True, alpha=0.3)\n    plt.savefig('training_curve.png', dpi=150)\n    plt.show()\nelse:\n    print(\"Skipping training (pretrained model loaded)\")\n    history = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T06:26:51.935977Z","iopub.execute_input":"2026-01-07T06:26:51.936651Z","iopub.status.idle":"2026-01-07T07:23:10.021083Z","shell.execute_reply.started":"2026-01-07T06:26:51.936627Z","shell.execute_reply":"2026-01-07T07:23:10.020400Z"}},"outputs":[{"name":"stdout","text":"\nTraining with T=16, Stride=2\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/25: 100%|██████████| 141/141 [02:13<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Loss = 0.010825\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/25: 100%|██████████| 141/141 [02:13<00:00,  1.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Loss = 0.004235\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/25: 100%|██████████| 141/141 [02:15<00:00,  1.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Loss = 0.004438\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/25: 100%|██████████| 141/141 [02:16<00:00,  1.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Loss = 0.014522\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/25: 100%|██████████| 141/141 [02:13<00:00,  1.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Loss = 0.006851\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/25: 100%|██████████| 141/141 [02:15<00:00,  1.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: Loss = 0.004501\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/25: 100%|██████████| 141/141 [02:14<00:00,  1.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: Loss = 0.003996\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/25: 100%|██████████| 141/141 [02:17<00:00,  1.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: Loss = 0.003809\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/25: 100%|██████████| 141/141 [02:17<00:00,  1.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: Loss = 0.003658\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/25: 100%|██████████| 141/141 [02:17<00:00,  1.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Loss = 0.003646\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/25: 100%|██████████| 141/141 [02:15<00:00,  1.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: Loss = 0.003508\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/25: 100%|██████████| 141/141 [02:17<00:00,  1.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: Loss = 0.003464\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/25: 100%|██████████| 141/141 [02:21<00:00,  1.00s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: Loss = 0.014838\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/25: 100%|██████████| 141/141 [02:18<00:00,  1.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14: Loss = 0.006377\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/25: 100%|██████████| 141/141 [02:14<00:00,  1.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15: Loss = 0.004477\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/25: 100%|██████████| 141/141 [02:15<00:00,  1.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16: Loss = 0.003959\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/25: 100%|██████████| 141/141 [02:14<00:00,  1.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17: Loss = 0.003744\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/25: 100%|██████████| 141/141 [02:11<00:00,  1.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18: Loss = 0.003635\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/25: 100%|██████████| 141/141 [02:14<00:00,  1.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19: Loss = 0.003546\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/25: 100%|██████████| 141/141 [02:13<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20: Loss = 0.003517\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/25: 100%|██████████| 141/141 [02:14<00:00,  1.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21: Loss = 0.003531\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/25: 100%|██████████| 141/141 [02:14<00:00,  1.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22: Loss = 0.003467\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/25: 100%|██████████| 141/141 [02:12<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23: Loss = 0.003441\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/25: 100%|██████████| 141/141 [02:13<00:00,  1.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24: Loss = 0.003436\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/25: 100%|██████████| 141/141 [02:11<00:00,  1.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25: Loss = 0.003402\nModel saved: trained_model.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":27},{"id":"5c6901e3-c687-4cc1-83e6-7e0e8c504fd1","cell_type":"markdown","source":"---\n## 7. Predictions\n---","metadata":{}},{"id":"6a2b7dfa-1581-410a-9329-a92ba3186960","cell_type":"code","source":"def predict_video(model, video_path, temporal_length, img_size, device):\n    \"\"\"\n    Compute reconstruction error for all frames.\n    Works with temporal_length=1 (single frame) and >1 (temporal cuboid).\n    \"\"\"\n    model.eval()\n    transform = transforms.Compose([transforms.Resize((img_size, img_size)), transforms.ToTensor()])\n    \n    frames = sorted([f for f in os.listdir(video_path) if f.endswith(('.jpg', '.png'))])\n    frame_errors = {i: [] for i in range(len(frames))}\n    \n    with torch.no_grad():\n        for start_idx in range(len(frames) - temporal_length + 1):\n            cuboid = []\n            for i in range(temporal_length):\n                img = Image.open(os.path.join(video_path, frames[start_idx + i])).convert('L')\n                cuboid.append(transform(img))\n            \n            cuboid = torch.cat(cuboid, dim=0).unsqueeze(0).to(device)\n            output = model(cuboid)\n            \n            # Per-frame error\n            error = (cuboid - output).pow(2).mean(dim=[2, 3]).squeeze().cpu().numpy()\n            \n            # Handle temporal_length=1 (scalar) vs >1 (array)\n            if temporal_length == 1:\n                frame_errors[start_idx].append(float(error))\n            else:\n                error = np.atleast_1d(error)  # Ensure it's always an array\n                for i in range(temporal_length):\n                    frame_errors[start_idx + i].append(error[i])\n    \n    return {idx: np.mean(errs) if errs else 0.0 for idx, errs in frame_errors.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T07:23:10.022300Z","iopub.execute_input":"2026-01-07T07:23:10.022558Z","iopub.status.idle":"2026-01-07T07:23:10.030319Z","shell.execute_reply.started":"2026-01-07T07:23:10.022532Z","shell.execute_reply":"2026-01-07T07:23:10.029777Z"}},"outputs":[],"execution_count":28},{"id":"42259f1d-7838-4292-ba6f-f5ef03315eca","cell_type":"code","source":"print(\"Processing test videos...\")\nraw_predictions = {}\n\ntest_folders = sorted([f for f in os.listdir(TEST_PATH) if os.path.isdir(os.path.join(TEST_PATH, f))])\n\nfor folder in tqdm(test_folders):\n    video_id = int(folder)\n    raw_predictions[video_id] = predict_video(\n        model, os.path.join(TEST_PATH, folder), TEMPORAL_LENGTH, IMG_SIZE, device\n    )\n\nprint(f\"Processed {len(raw_predictions)} videos\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T07:23:10.031165Z","iopub.execute_input":"2026-01-07T07:23:10.031449Z","iopub.status.idle":"2026-01-07T07:32:26.616859Z","shell.execute_reply.started":"2026-01-07T07:23:10.031426Z","shell.execute_reply":"2026-01-07T07:32:26.616280Z"}},"outputs":[{"name":"stdout","text":"Processing test videos...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 21/21 [09:16<00:00, 26.50s/it]","output_type":"stream"},{"name":"stdout","text":"Processed 21 videos\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":29},{"id":"9e603d2d-6a59-406c-8bff-4a68cb74e42f","cell_type":"markdown","source":"---\n## 8. Submission\n---","metadata":{}},{"id":"aaaddee0-c493-4184-ad06-9215c678534d","cell_type":"code","source":"def normalize_predictions_globally(raw_preds):\n    # 1. Collect ALL errors from the entire dataset into one giant list\n    all_errors = []\n    for vid in raw_preds:\n        all_errors.extend(raw_preds[vid].values())\n    \n    # 2. Calculate Global Thresholds (99.5th percentile is safer for \"rare\" anomalies)\n    # Using 99.5 instead of 95 because real anomalies are rare!\n    global_min = np.min(all_errors);\n    global_max = np.percentile(all_errors, 100) \n    \n    print(f\"Global Range: {global_min:.6f} to {global_max:.6f} (Capped at 99.5%)\")\n    \n    normalized = {}\n    for vid, errors in raw_preds.items():\n        normalized[vid] = {}\n        for frame_idx, e in errors.items():\n            # 3. Normalize everyone against the GLOBAL standard\n            score = (e - global_min) / (global_max - global_min)\n            normalized[vid][frame_idx] = np.clip(score, 0, 1)\n            \n    return normalized\n\n# Apply it\nnormalized_predictions = normalize_predictions_globally(raw_predictions)\nprint(\"Globally Normalized!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T07:32:27.212315Z","iopub.execute_input":"2026-01-07T07:32:27.212583Z","iopub.status.idle":"2026-01-07T07:32:27.271156Z","shell.execute_reply.started":"2026-01-07T07:32:27.212562Z","shell.execute_reply":"2026-01-07T07:32:27.270670Z"}},"outputs":[{"name":"stdout","text":"Global Range: 0.000549 to 0.026521 (Capped at 99.5%)\nGlobally Normalized!\n","output_type":"stream"}],"execution_count":31},{"id":"fc49fdea-f6bf-461c-b1bf-5f831823a58c","cell_type":"code","source":"def create_submission(norm_preds, test_path):\n    rows = []\n    for vid in sorted(norm_preds.keys()):\n        folder = f\"{vid:02d}\"\n        frames = sorted([f for f in os.listdir(os.path.join(test_path, folder)) if f.endswith(('.jpg', '.png'))])\n        for idx in sorted(norm_preds[vid].keys()):\n            if idx < len(frames):\n                frame_num = int(os.path.splitext(frames[idx])[0].replace('frame_', ''))\n            else:\n                frame_num = idx + 1\n            rows.append({'Id': f\"{vid}_{frame_num}\", 'Predicted': round(norm_preds[vid][idx], 6)})\n    \n    df = pd.DataFrame(rows)\n    df['_v'] = df['Id'].apply(lambda x: int(x.split('_')[0]))\n    df['_f'] = df['Id'].apply(lambda x: int(x.split('_')[1]))\n    df = df.sort_values(['_v', '_f'])[['Id', 'Predicted']]\n    df.to_csv('submission.csv', index=False)\n    print(f\"Saved: submission.csv ({len(df)} rows)\")\n    print(df.head(10))\n    return df\n\nsubmission_df = create_submission(normalized_predictions, TEST_PATH)","metadata":{"execution":{"iopub.status.busy":"2026-01-07T07:32:28.972689Z","iopub.execute_input":"2026-01-07T07:32:28.972961Z","iopub.status.idle":"2026-01-07T07:32:29.139856Z","shell.execute_reply.started":"2026-01-07T07:32:28.972937Z","shell.execute_reply":"2026-01-07T07:32:29.139283Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Saved: submission.csv (11706 rows)\n      Id  Predicted\n0  1_939   0.859282\n1  1_940   0.912128\n2  1_941   0.965811\n3  1_942   1.000000\n4  1_943   0.979438\n5  1_944   0.942812\n6  1_945   0.872322\n7  1_946   0.845084\n8  1_947   0.753562\n9  1_948   0.690928\n","output_type":"stream"}],"execution_count":33},{"id":"3214bea0-a16f-49c5-ab18-5cc0b1e04cb0","cell_type":"code","source":"# ============================================================\n# TEMPORAL SMOOTHING\n# ============================================================\n\nfrom scipy.ndimage import uniform_filter1d\n\ndef smooth_predictions(norm_preds, window=15):\n    smoothed = {}\n    for vid, errors in norm_preds.items():\n        indices = sorted(errors.keys())\n        values = np.array([errors[i] for i in indices])\n        smooth_values = uniform_filter1d(values, size=window)\n        smoothed[vid] = {i: smooth_values[j] for j, i in enumerate(indices)}\n    return smoothed\n\n# Apply smoothing\nsmoothed_predictions = smooth_predictions(normalized_predictions, window=5)\nprint(\"Temporal smoothing applied!\")\n\n# Create submission with smoothed predictions\nsubmission_df = create_submission(smoothed_predictions, TEST_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T07:32:29.140772Z","iopub.execute_input":"2026-01-07T07:32:29.141013Z","iopub.status.idle":"2026-01-07T07:32:29.440798Z","shell.execute_reply.started":"2026-01-07T07:32:29.140991Z","shell.execute_reply":"2026-01-07T07:32:29.439983Z"}},"outputs":[{"name":"stdout","text":"Temporal smoothing applied!\nSaved: submission.csv (11706 rows)\n      Id  Predicted\n0  1_939   0.901726\n1  1_940   0.919300\n2  1_941   0.943332\n3  1_942   0.960038\n4  1_943   0.952076\n5  1_944   0.927931\n6  1_945   0.878643\n7  1_946   0.820941\n8  1_947   0.761356\n9  1_948   0.706922\n","output_type":"stream"}],"execution_count":34}]}