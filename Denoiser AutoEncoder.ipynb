{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":126766,"databundleVersionId":15067517,"sourceType":"competition"}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pixel Play '26: Complete Pipeline\n\n## Steps:\n1. **Flip Detection & Correction** - Train CNN to detect and fix flipped frames\n2. **Denoising Autoencoder** - Train autoencoder with Input=Noisy, Target=Clean\n3. **Anomaly Detection** - Use reconstruction error as anomaly score\n4. **Submission** - Normalize, smooth, and create CSV","metadata":{}},{"cell_type":"markdown","source":"---\n## Cell 1: Imports & Setup","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport shutil\nfrom tqdm import tqdm\nimport random\nimport re\nimport zipfile\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torchvision.transforms.functional as TF\nimport pandas as pd\nfrom scipy.ndimage import uniform_filter1d\n\n# Seeds\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T14:05:23.506374Z","iopub.execute_input":"2025-12-29T14:05:23.507209Z","iopub.status.idle":"2025-12-29T14:05:23.515364Z","shell.execute_reply.started":"2025-12-29T14:05:23.507162Z","shell.execute_reply":"2025-12-29T14:05:23.514540Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"---\n## Cell 2: Configuration (EDIT THIS!)","metadata":{}},{"cell_type":"code","source":"# ====================\n# PATHS\n# ====================\nTRAIN_PATH = '/kaggle/input/pixel-play-26/Avenue_Corrupted-20251221T112159Z-3-001/Avenue_Corrupted/Dataset/training_videos'\nTEST_PATH_ORIGINAL = '/kaggle/input/pixel-play-26/Avenue_Corrupted-20251221T112159Z-3-001/Avenue_Corrupted/Dataset/testing_videos'\n\n# Intermediate: After flip correction\nFLIP_CLEANED_PATH = '/kaggle/working/flip_cleaned_testing_videos'\n\n# ====================\n# MODE SELECTION\n# ====================\nCOLOR_MODE = 'grayscale'  # Options: 'grayscale' or 'rgb'\n\n# ====================\n# FLIP DETECTOR CONFIG\n# ====================\nFLIP_EPOCHS = 5\nFLIP_BATCH_SIZE = 64\nFLIP_LR = 0.001\nFLIP_IMG_SIZE = 64\nFLIP_SAMPLES = 3000\n\n# ====================\n# NOISE CONFIG (Matching your test data)\n# ====================\n# Grayscale noise\nNOISE_STRENGTH_GRAY = 40  # In 0-255 scale\n\n# RGB noise (per channel)\nNOISE_STRENGTH_R = 35\nNOISE_STRENGTH_G = 35\nNOISE_STRENGTH_B = 35\n\nNOISE_MODE = \"symmetric\"  # \"symmetric\" => U(-A,+A), \"positive\" => U(0,+A)\n\n# ====================\n# DENOISING AUTOENCODER CONFIG\n# ====================\nIMG_SIZE = 128\nTEMPORAL_LENGTH = 16\nSTRIDE = 2\nBATCH_SIZE = 32\nEPOCHS = 25\nLEARNING_RATE = 0.001\n\n# ====================\n# TEMPORAL SMOOTHING\n# ====================\nSMOOTHING_WINDOW = 15\n\n# ====================\n# OUTPUT CONFIG\n# ====================\nMODEL_SAVE_NAME = 'denoising_autoencoder.pth'\nFLIP_MODEL_NAME = 'flip_detector.pth'\nSUBMISSION_FILE = 'submission.csv'\nOUTPUT_ZIP = 'pixelplay_output.zip'\n\n# ====================\n# PRINT CONFIG\n# ====================\nprint(\"=\"*60)\nprint(\"CONFIGURATION\")\nprint(\"=\"*60)\nprint(f\"Color Mode: {COLOR_MODE}\")\nprint(f\"\\nNoise Settings:\")\nif COLOR_MODE == 'grayscale':\n    print(f\"  Grayscale Strength: {NOISE_STRENGTH_GRAY}\")\nelse:\n    print(f\"  R Channel: {NOISE_STRENGTH_R}\")\n    print(f\"  G Channel: {NOISE_STRENGTH_G}\")\n    print(f\"  B Channel: {NOISE_STRENGTH_B}\")\nprint(f\"  Mode: {NOISE_MODE}\")\nprint(f\"\\nModel Settings:\")\nprint(f\"  Image Size: {IMG_SIZE}\")\nprint(f\"  Temporal Length: {TEMPORAL_LENGTH}\")\nprint(f\"  Stride: {STRIDE}\")\nprint(f\"  Epochs: {EPOCHS}\")\nprint(f\"  Smoothing Window: {SMOOTHING_WINDOW}\")\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T14:05:23.516731Z","iopub.execute_input":"2025-12-29T14:05:23.516973Z","iopub.status.idle":"2025-12-29T14:05:23.538367Z","shell.execute_reply.started":"2025-12-29T14:05:23.516950Z","shell.execute_reply":"2025-12-29T14:05:23.537691Z"}},"outputs":[{"name":"stdout","text":"============================================================\nCONFIGURATION\n============================================================\nColor Mode: grayscale\n\nNoise Settings:\n  Grayscale Strength: 40\n  Mode: symmetric\n\nModel Settings:\n  Image Size: 128\n  Temporal Length: 16\n  Stride: 2\n  Epochs: 25\n  Smoothing Window: 15\n============================================================\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"---\n## Cell 3: Noise Functions","metadata":{}},{"cell_type":"code","source":"def add_uniform_grayscale_noise(x, strength=35, mode=\"symmetric\"):\n    \"\"\"\n    Add uniform noise to grayscale tensor.\n    \n    Args:\n        x: tensor in range [0,1] -> shape (B, T, H, W) or (T, H, W)\n        strength: max noise value in 0-255 scale\n        mode: \"symmetric\" => U(-A,+A), \"positive\" => U(0,+A)\n    \n    Returns:\n        Noisy tensor clamped to [0,1]\n    \"\"\"\n    A = strength / 255.0\n    if mode == \"symmetric\":\n        noise = torch.empty_like(x).uniform_(-A, A)\n    else:\n        noise = torch.empty_like(x).uniform_(0, A)\n    noisy = x + noise\n    noisy = torch.clamp(noisy, 0.0, 1.0)\n    return noisy\n\n\ndef add_uniform_rgb_noise(x, strength_r=35, strength_g=35, strength_b=35, mode=\"symmetric\"):\n    \"\"\"\n    Add uniform noise to RGB tensor (per channel).\n    \n    Args:\n        x: tensor in range [0,1] -> shape (B, T*3, H, W) or (T*3, H, W)\n        strength_r/g/b: max noise value in 0-255 scale per channel\n        mode: \"symmetric\" => U(-A,+A), \"positive\" => U(0,+A)\n    \n    Returns:\n        Noisy tensor clamped to [0,1]\n    \"\"\"\n    A_r = strength_r / 255.0\n    A_g = strength_g / 255.0\n    A_b = strength_b / 255.0\n    \n    noisy = x.clone()\n    \n    # Handle batched (B, T*3, H, W)\n    if len(x.shape) == 4:\n        channels = x.shape[1]\n        t = channels // 3\n        for i in range(t):\n            idx_r, idx_g, idx_b = i*3, i*3+1, i*3+2\n            if mode == \"symmetric\":\n                noisy[:, idx_r] += torch.empty_like(x[:, idx_r]).uniform_(-A_r, A_r)\n                noisy[:, idx_g] += torch.empty_like(x[:, idx_g]).uniform_(-A_g, A_g)\n                noisy[:, idx_b] += torch.empty_like(x[:, idx_b]).uniform_(-A_b, A_b)\n            else:\n                noisy[:, idx_r] += torch.empty_like(x[:, idx_r]).uniform_(0, A_r)\n                noisy[:, idx_g] += torch.empty_like(x[:, idx_g]).uniform_(0, A_g)\n                noisy[:, idx_b] += torch.empty_like(x[:, idx_b]).uniform_(0, A_b)\n    # Handle single sample (T*3, H, W)\n    else:\n        channels = x.shape[0]\n        t = channels // 3\n        for i in range(t):\n            idx_r, idx_g, idx_b = i*3, i*3+1, i*3+2\n            if mode == \"symmetric\":\n                noisy[idx_r] += torch.empty_like(x[idx_r]).uniform_(-A_r, A_r)\n                noisy[idx_g] += torch.empty_like(x[idx_g]).uniform_(-A_g, A_g)\n                noisy[idx_b] += torch.empty_like(x[idx_b]).uniform_(-A_b, A_b)\n            else:\n                noisy[idx_r] += torch.empty_like(x[idx_r]).uniform_(0, A_r)\n                noisy[idx_g] += torch.empty_like(x[idx_g]).uniform_(0, A_g)\n                noisy[idx_b] += torch.empty_like(x[idx_b]).uniform_(0, A_b)\n    \n    noisy = torch.clamp(noisy, 0.0, 1.0)\n    return noisy\n\n\ndef add_noise(x, color_mode='grayscale'):\n    \"\"\"Wrapper function to add noise based on color mode.\"\"\"\n    if color_mode == 'grayscale':\n        return add_uniform_grayscale_noise(x, NOISE_STRENGTH_GRAY, NOISE_MODE)\n    else:\n        return add_uniform_rgb_noise(x, NOISE_STRENGTH_R, NOISE_STRENGTH_G, NOISE_STRENGTH_B, NOISE_MODE)\n\nprint(\"Noise functions defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T14:05:23.539153Z","iopub.execute_input":"2025-12-29T14:05:23.539449Z","iopub.status.idle":"2025-12-29T14:05:23.560371Z","shell.execute_reply.started":"2025-12-29T14:05:23.539425Z","shell.execute_reply":"2025-12-29T14:05:23.559512Z"}},"outputs":[{"name":"stdout","text":"Noise functions defined!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"---\n## Cell 4: Flip Detector Dataset & Model","metadata":{}},{"cell_type":"code","source":"class FlipDetectionDataset(Dataset):\n    \"\"\"Dataset: Normal (0) vs Flipped (1)\"\"\"\n    \n    def __init__(self, video_path, samples_per_class=3000):\n        self.transform = transforms.Compose([\n            transforms.Resize((FLIP_IMG_SIZE, FLIP_IMG_SIZE)),\n            transforms.ToTensor(),\n        ])\n        \n        self.frame_paths = []\n        for folder in os.listdir(video_path):\n            folder_path = os.path.join(video_path, folder)\n            if os.path.isdir(folder_path):\n                for frame in os.listdir(folder_path):\n                    if frame.endswith(('.jpg', '.png')):\n                        self.frame_paths.append(os.path.join(folder_path, frame))\n        \n        print(f\"Total frames: {len(self.frame_paths)}\")\n        \n        selected = random.sample(self.frame_paths, min(samples_per_class, len(self.frame_paths)))\n        \n        self.samples = []\n        for path in selected:\n            self.samples.append((path, 0))  # Normal\n            self.samples.append((path, 1))  # Flipped\n        random.shuffle(self.samples)\n        print(f\"Training samples: {len(self.samples)}\")\n    \n    def __len__(self):\n        return len(self.samples)\n    \n    def __getitem__(self, idx):\n        path, label = self.samples[idx]\n        img = Image.open(path).convert('L')\n        img_tensor = self.transform(img)\n        if label == 1:\n            img_tensor = TF.vflip(img_tensor)\n        return img_tensor, torch.tensor(label, dtype=torch.long)\n\n\nclass FlipDetectorCNN(nn.Module):\n    \"\"\"Small CNN for flip detection\"\"\"\n    \n    def __init__(self):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(1, 16, 3, 2, 1), nn.ReLU(),\n            nn.Conv2d(16, 32, 3, 2, 1), nn.ReLU(),\n            nn.Conv2d(32, 64, 3, 2, 1), nn.ReLU(),\n            nn.AdaptiveAvgPool2d(1),\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(64, 32), nn.ReLU(), nn.Dropout(0.3),\n            nn.Linear(32, 2),\n        )\n    \n    def forward(self, x):\n        return self.classifier(self.features(x))\n\nprint(\"Flip detector classes defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T14:05:23.561963Z","iopub.execute_input":"2025-12-29T14:05:23.562183Z","iopub.status.idle":"2025-12-29T14:05:23.588018Z","shell.execute_reply.started":"2025-12-29T14:05:23.562162Z","shell.execute_reply":"2025-12-29T14:05:23.587292Z"}},"outputs":[{"name":"stdout","text":"Flip detector classes defined!\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"---\n## Cell 5: Train Flip Detector","metadata":{}},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*60)\nprint(\"STEP 1: TRAINING FLIP DETECTOR\")\nprint(\"=\"*60)\n\nflip_dataset = FlipDetectionDataset(TRAIN_PATH, FLIP_SAMPLES)\nflip_loader = DataLoader(flip_dataset, batch_size=FLIP_BATCH_SIZE, shuffle=True, num_workers=2)\n\nflip_model = FlipDetectorCNN().to(device)\nflip_criterion = nn.CrossEntropyLoss()\nflip_optimizer = optim.Adam(flip_model.parameters(), lr=FLIP_LR)\n\nprint(f\"Parameters: {sum(p.numel() for p in flip_model.parameters()):,}\")\n\nflip_model.train()\nfor epoch in range(FLIP_EPOCHS):\n    total_loss, correct, total = 0, 0, 0\n    pbar = tqdm(flip_loader, desc=f'Flip Epoch {epoch+1}/{FLIP_EPOCHS}')\n    for images, labels in pbar:\n        images, labels = images.to(device), labels.to(device)\n        outputs = flip_model(images)\n        loss = flip_criterion(outputs, labels)\n        flip_optimizer.zero_grad()\n        loss.backward()\n        flip_optimizer.step()\n        total_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100*correct/total:.1f}%'})\n    print(f'Epoch {epoch+1}: Loss={total_loss/len(flip_loader):.4f}, Acc={100*correct/total:.1f}%')\n\ntorch.save(flip_model.state_dict(), FLIP_MODEL_NAME)\nprint(f\"Saved: {FLIP_MODEL_NAME}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T14:05:23.656540Z","iopub.execute_input":"2025-12-29T14:05:23.656764Z","iopub.status.idle":"2025-12-29T14:06:41.217924Z","shell.execute_reply.started":"2025-12-29T14:05:23.656742Z","shell.execute_reply":"2025-12-29T14:06:41.216920Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nSTEP 1: TRAINING FLIP DETECTOR\n============================================================\nTotal frames: 9204\nTraining samples: 6000\nParameters: 25,442\n","output_type":"stream"},{"name":"stderr","text":"Flip Epoch 1/5: 100%|██████████| 94/94 [00:24<00:00,  3.87it/s, loss=0.5508, acc=63.6%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Loss=0.6721, Acc=63.6%\n","output_type":"stream"},{"name":"stderr","text":"Flip Epoch 2/5: 100%|██████████| 94/94 [00:13<00:00,  6.94it/s, loss=0.0077, acc=99.3%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Loss=0.1302, Acc=99.3%\n","output_type":"stream"},{"name":"stderr","text":"Flip Epoch 3/5: 100%|██████████| 94/94 [00:13<00:00,  6.90it/s, loss=0.0020, acc=100.0%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Loss=0.0052, Acc=100.0%\n","output_type":"stream"},{"name":"stderr","text":"Flip Epoch 4/5: 100%|██████████| 94/94 [00:13<00:00,  7.15it/s, loss=0.0002, acc=100.0%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Loss=0.0019, Acc=100.0%\n","output_type":"stream"},{"name":"stderr","text":"Flip Epoch 5/5: 100%|██████████| 94/94 [00:12<00:00,  7.31it/s, loss=0.0009, acc=100.0%]","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Loss=0.0018, Acc=100.0%\nSaved: flip_detector.pth\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"---\n## Cell 6: Correct Flipped Test Frames","metadata":{}},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*60)\nprint(\"STEP 2: CORRECTING FLIPPED FRAMES\")\nprint(\"=\"*60)\n\nflip_model.eval()\nflip_transform = transforms.Compose([\n    transforms.Resize((FLIP_IMG_SIZE, FLIP_IMG_SIZE)),\n    transforms.ToTensor(),\n])\n\nif os.path.exists(FLIP_CLEANED_PATH):\n    shutil.rmtree(FLIP_CLEANED_PATH)\nos.makedirs(FLIP_CLEANED_PATH)\n\nflipped_count = 0\ntotal_count = 0\n\nvideo_folders = sorted([f for f in os.listdir(TEST_PATH_ORIGINAL) \n                        if os.path.isdir(os.path.join(TEST_PATH_ORIGINAL, f))])\n\nwith torch.no_grad():\n    for folder in tqdm(video_folders, desc='Correcting flips'):\n        src_folder = os.path.join(TEST_PATH_ORIGINAL, folder)\n        dst_folder = os.path.join(FLIP_CLEANED_PATH, folder)\n        os.makedirs(dst_folder, exist_ok=True)\n        \n        frames = sorted([f for f in os.listdir(src_folder) if f.endswith(('.jpg', '.png'))])\n        \n        for frame_name in frames:\n            src_path = os.path.join(src_folder, frame_name)\n            dst_path = os.path.join(dst_folder, frame_name)\n            \n            img_gray = Image.open(src_path).convert('L')\n            img_tensor = flip_transform(img_gray).unsqueeze(0).to(device)\n            output = flip_model(img_tensor)\n            is_flipped = torch.softmax(output, dim=1)[0, 1].item() > 0.5\n            \n            img_original = Image.open(src_path)\n            \n            if is_flipped:\n                img_corrected = TF.vflip(transforms.ToTensor()(img_original))\n                transforms.ToPILImage()(img_corrected).save(dst_path)\n                flipped_count += 1\n            else:\n                shutil.copy2(src_path, dst_path)\n            \n            total_count += 1\n\nprint(f\"\\nFlipped corrected: {flipped_count} ({100*flipped_count/total_count:.1f}%)\")\nprint(f\"Total frames: {total_count}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T14:06:41.219678Z","iopub.execute_input":"2025-12-29T14:06:41.219928Z","iopub.status.idle":"2025-12-29T14:09:39.042447Z","shell.execute_reply.started":"2025-12-29T14:06:41.219898Z","shell.execute_reply":"2025-12-29T14:09:39.041765Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nSTEP 2: CORRECTING FLIPPED FRAMES\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Correcting flips: 100%|██████████| 21/21 [02:57<00:00,  8.47s/it]","output_type":"stream"},{"name":"stdout","text":"\nFlipped corrected: 1195 (10.2%)\nTotal frames: 11706\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"---\n## Cell 7: Denoising Autoencoder Dataset","metadata":{}},{"cell_type":"code","source":"class DenoisingVideoDataset(Dataset):\n    \"\"\"\n    Denoising Dataset: Input=Noisy, Target=Clean\n    Supports grayscale and RGB modes.\n    \"\"\"\n    \n    def __init__(self, video_path, temporal_length=10, stride=1, img_size=128,\n                 color_mode='grayscale', is_train=True):\n        self.video_path = video_path\n        self.temporal_length = temporal_length\n        self.stride = stride\n        self.img_size = img_size\n        self.color_mode = color_mode\n        self.is_train = is_train\n        \n        self.transform = transforms.Compose([\n            transforms.Resize((img_size, img_size)),\n            transforms.ToTensor()\n        ])\n        \n        self.samples = []\n        self._prepare_samples()\n    \n    def _prepare_samples(self):\n        video_folders = sorted([f for f in os.listdir(self.video_path)\n                               if os.path.isdir(os.path.join(self.video_path, f))])\n        \n        for folder in video_folders:\n            folder_path = os.path.join(self.video_path, folder)\n            frames = sorted([f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png'))])\n            max_start = len(frames) - self.temporal_length\n            for start_idx in range(0, max_start + 1, self.stride):\n                self.samples.append((folder, start_idx))\n        \n        print(f\"Dataset: {len(self.samples)} samples (T={self.temporal_length}, stride={self.stride}, mode={self.color_mode})\")\n    \n    def __len__(self):\n        return len(self.samples)\n    \n    def __getitem__(self, idx):\n        folder, start_idx = self.samples[idx]\n        folder_path = os.path.join(self.video_path, folder)\n        frames = sorted([f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png'))])\n        \n        clean_frames = []\n        for i in range(self.temporal_length):\n            frame_path = os.path.join(folder_path, frames[start_idx + i])\n            if self.color_mode == 'grayscale':\n                img = Image.open(frame_path).convert('L')\n            else:\n                img = Image.open(frame_path).convert('RGB')\n            clean_frames.append(self.transform(img))\n        \n        clean_cuboid = torch.cat(clean_frames, dim=0)\n        \n        if self.is_train:\n            noisy_cuboid = add_noise(clean_cuboid.unsqueeze(0), self.color_mode).squeeze(0)\n            return noisy_cuboid, clean_cuboid\n        else:\n            return clean_cuboid, clean_cuboid\n\nprint(\"Denoising dataset class defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T14:09:39.043431Z","iopub.execute_input":"2025-12-29T14:09:39.043701Z","iopub.status.idle":"2025-12-29T14:09:39.055399Z","shell.execute_reply.started":"2025-12-29T14:09:39.043663Z","shell.execute_reply":"2025-12-29T14:09:39.054804Z"}},"outputs":[{"name":"stdout","text":"Denoising dataset class defined!\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"---\n## Cell 8: Denoising Autoencoder Model","metadata":{}},{"cell_type":"code","source":"class DenoisingConvAutoencoder(nn.Module):\n    \"\"\"\n    Denoising Autoencoder\n    Grayscale: channels = T\n    RGB: channels = T * 3\n    \"\"\"\n    \n    def __init__(self, temporal_length=10, color_mode='grayscale'):\n        super().__init__()\n        \n        in_ch = temporal_length if color_mode == 'grayscale' else temporal_length * 3\n        self.in_channels = in_ch\n        \n        self.encoder = nn.Sequential(\n            nn.Conv2d(in_ch, 64, 3, 2, 1), nn.ReLU(True),\n            nn.Conv2d(64, 128, 3, 2, 1), nn.ReLU(True),\n            nn.Conv2d(128, 256, 3, 2, 1), nn.ReLU(True),\n            nn.Conv2d(256, 512, 3, 2, 1), nn.ReLU(True),\n        )\n        \n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(512, 256, 3, 2, 1, 1), nn.ReLU(True),\n            nn.ConvTranspose2d(256, 128, 3, 2, 1, 1), nn.ReLU(True),\n            nn.ConvTranspose2d(128, 64, 3, 2, 1, 1), nn.ReLU(True),\n            nn.ConvTranspose2d(64, in_ch, 3, 2, 1, 1), nn.Sigmoid(),\n        )\n    \n    def forward(self, x):\n        return self.decoder(self.encoder(x))\n\nprint(\"Denoising autoencoder model defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T14:09:39.057028Z","iopub.execute_input":"2025-12-29T14:09:39.057367Z","iopub.status.idle":"2025-12-29T14:09:39.078677Z","shell.execute_reply.started":"2025-12-29T14:09:39.057330Z","shell.execute_reply":"2025-12-29T14:09:39.078015Z"}},"outputs":[{"name":"stdout","text":"Denoising autoencoder model defined!\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"---\n## Cell 9: Train Denoising Autoencoder","metadata":{}},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*60)\nprint(\"STEP 3: TRAINING DENOISING AUTOENCODER\")\nprint(\"=\"*60)\nprint(f\"Mode: {COLOR_MODE} | Noise: {NOISE_STRENGTH_GRAY if COLOR_MODE == 'grayscale' else 'RGB'}\")\n\ntrain_dataset = DenoisingVideoDataset(\n    TRAIN_PATH, TEMPORAL_LENGTH, STRIDE, IMG_SIZE, COLOR_MODE, is_train=True\n)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n\nmodel = DenoisingConvAutoencoder(TEMPORAL_LENGTH, COLOR_MODE).to(device)\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\nprint(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n\nmodel.train()\ntrain_losses = []\n\nfor epoch in range(EPOCHS):\n    total_loss = 0\n    pbar = tqdm(train_loader, desc=f'Denoise Epoch {epoch+1}/{EPOCHS}')\n    \n    for noisy_input, clean_target in pbar:\n        noisy_input, clean_target = noisy_input.to(device), clean_target.to(device)\n        output = model(noisy_input)\n        loss = criterion(output, clean_target)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        pbar.set_postfix({'loss': f'{loss.item():.6f}'})\n    \n    epoch_loss = total_loss / len(train_loader)\n    train_losses.append(epoch_loss)\n    print(f'Epoch {epoch+1}: Loss={epoch_loss:.6f}')\n\ntorch.save(model.state_dict(), MODEL_SAVE_NAME)\nprint(f\"Saved: {MODEL_SAVE_NAME}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T14:09:39.079698Z","iopub.execute_input":"2025-12-29T14:09:39.079988Z","iopub.status.idle":"2025-12-29T14:54:19.228457Z","shell.execute_reply.started":"2025-12-29T14:09:39.079958Z","shell.execute_reply":"2025-12-29T14:54:19.226999Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nSTEP 3: TRAINING DENOISING AUTOENCODER\n============================================================\nMode: grayscale | Noise: 40\nDataset: 4486 samples (T=16, stride=2, mode=grayscale)\nParameters: 3,116,432\n","output_type":"stream"},{"name":"stderr","text":"Denoise Epoch 1/25: 100%|██████████| 141/141 [03:22<00:00,  1.43s/it, loss=0.004401]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Loss=0.016458\n","output_type":"stream"},{"name":"stderr","text":"Denoise Epoch 2/25: 100%|██████████| 141/141 [02:47<00:00,  1.19s/it, loss=0.002445]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Loss=0.002995\n","output_type":"stream"},{"name":"stderr","text":"Denoise Epoch 3/25: 100%|██████████| 141/141 [02:51<00:00,  1.22s/it, loss=0.001830]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Loss=0.001948\n","output_type":"stream"},{"name":"stderr","text":"Denoise Epoch 4/25: 100%|██████████| 141/141 [02:52<00:00,  1.22s/it, loss=0.001567]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Loss=0.001562\n","output_type":"stream"},{"name":"stderr","text":"Denoise Epoch 5/25: 100%|██████████| 141/141 [02:52<00:00,  1.22s/it, loss=0.001169]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Loss=0.001388\n","output_type":"stream"},{"name":"stderr","text":"Denoise Epoch 6/25: 100%|██████████| 141/141 [02:55<00:00,  1.24s/it, loss=0.000921]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: Loss=0.001202\n","output_type":"stream"},{"name":"stderr","text":"Denoise Epoch 7/25: 100%|██████████| 141/141 [02:54<00:00,  1.24s/it, loss=0.001036]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: Loss=0.001141\n","output_type":"stream"},{"name":"stderr","text":"Denoise Epoch 8/25: 100%|██████████| 141/141 [02:59<00:00,  1.27s/it, loss=0.001043]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: Loss=0.001066\n","output_type":"stream"},{"name":"stderr","text":"Denoise Epoch 9/25: 100%|██████████| 141/141 [02:56<00:00,  1.25s/it, loss=0.000935]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: Loss=0.001009\n","output_type":"stream"},{"name":"stderr","text":"Denoise Epoch 10/25: 100%|██████████| 141/141 [02:59<00:00,  1.27s/it, loss=0.000817]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Loss=0.000979\n","output_type":"stream"},{"name":"stderr","text":"Denoise Epoch 11/25: 100%|██████████| 141/141 [02:58<00:00,  1.27s/it, loss=0.001273]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: Loss=0.000935\n","output_type":"stream"},{"name":"stderr","text":"Denoise Epoch 12/25: 100%|██████████| 141/141 [02:54<00:00,  1.24s/it, loss=0.000803]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: Loss=0.000908\n","output_type":"stream"},{"name":"stderr","text":"Denoise Epoch 13/25: 100%|██████████| 141/141 [02:58<00:00,  1.27s/it, loss=0.000703]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: Loss=0.000875\n","output_type":"stream"},{"name":"stderr","text":"Denoise Epoch 14/25: 100%|██████████| 141/141 [02:55<00:00,  1.24s/it, loss=0.000797]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14: Loss=0.000845\n","output_type":"stream"},{"name":"stderr","text":"Denoise Epoch 15/25: 100%|██████████| 141/141 [03:04<00:00,  1.31s/it, loss=0.000942]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15: Loss=0.000847\n","output_type":"stream"},{"name":"stderr","text":"Denoise Epoch 16/25:  10%|▉         | 14/141 [00:18<02:45,  1.30s/it, loss=0.000861]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2732967675.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Denoise Epoch {epoch+1}/{EPOCHS}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mnoisy_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_target\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mnoisy_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoisy_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1454\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1455\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":14},{"cell_type":"markdown","source":"---\n## Cell 10: Plot Training Curve","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 4))\nplt.plot(train_losses, 'b-', linewidth=2)\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Denoising Autoencoder Training')\nplt.grid(True, alpha=0.3)\nplt.savefig('training_curve.png', dpi=150)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T14:54:26.624496Z","iopub.execute_input":"2025-12-29T14:54:26.624806Z","iopub.status.idle":"2025-12-29T14:54:26.975790Z","shell.execute_reply.started":"2025-12-29T14:54:26.624775Z","shell.execute_reply":"2025-12-29T14:54:26.975112Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x400 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"---\n## Cell 11: Prediction Functions","metadata":{}},{"cell_type":"code","source":"def extract_frame_number(filename):\n    match = re.search(r'(\\d+)', os.path.splitext(filename)[0])\n    return int(match.group(1)) if match else 0\n\n\ndef predict_video(model, video_path, temporal_length, img_size, color_mode, device):\n    model.eval()\n    transform = transforms.Compose([transforms.Resize((img_size, img_size)), transforms.ToTensor()])\n    \n    frames = sorted([f for f in os.listdir(video_path) if f.endswith(('.jpg', '.png'))])\n    frame_errors = {i: [] for i in range(len(frames))}\n    \n    with torch.no_grad():\n        for start_idx in range(len(frames) - temporal_length + 1):\n            cuboid_frames = []\n            for i in range(temporal_length):\n                frame_path = os.path.join(video_path, frames[start_idx + i])\n                if color_mode == 'grayscale':\n                    img = Image.open(frame_path).convert('L')\n                else:\n                    img = Image.open(frame_path).convert('RGB')\n                cuboid_frames.append(transform(img))\n            \n            cuboid = torch.cat(cuboid_frames, dim=0).unsqueeze(0).to(device)\n            output = model(cuboid)\n            \n            if color_mode == 'grayscale':\n                error = (cuboid - output).pow(2).mean(dim=[2, 3]).squeeze().cpu().numpy()\n            else:\n                error = (cuboid - output).pow(2).view(-1, temporal_length, 3, img_size, img_size)\n                error = error.mean(dim=[2, 3, 4]).squeeze().cpu().numpy()\n            \n            if temporal_length == 1:\n                frame_errors[start_idx].append(float(error))\n            else:\n                error = np.atleast_1d(error)\n                for i in range(temporal_length):\n                    frame_errors[start_idx + i].append(error[i])\n    \n    avg_errors = {idx: np.mean(errs) if errs else 0.0 for idx, errs in frame_errors.items()}\n    \n    frame_scores = {}\n    for idx, frame_name in enumerate(frames):\n        frame_scores[extract_frame_number(frame_name)] = avg_errors.get(idx, 0.0)\n    \n    return frame_scores\n\n\ndef normalize_predictions_global(raw_preds):\n    \"\"\"Global normalization across ALL videos.\"\"\"\n    # Collect ALL scores\n    all_scores = []\n    for vid, scores in raw_preds.items():\n        all_scores.extend(scores.values())\n    \n    all_scores = np.array(all_scores)\n    p5, p95 = np.percentile(all_scores, [1, 100])  # ← Global percentiles\n    \n    normalized = {}\n    for vid, scores in raw_preds.items():\n        if p95 > p5:\n            normalized[vid] = {f: np.clip((s - p5) / (p95 - p5), 0, 1) for f, s in scores.items()}\n        else:\n            normalized[vid] = {f: 0.5 for f in scores}\n    \n    return normalized\n\n\ndef smooth_predictions(norm_preds, window=5):\n    smoothed = {}\n    for vid, errors in norm_preds.items():\n        indices = sorted(errors.keys())\n        values = np.array([errors[i] for i in indices])\n        smooth_values = uniform_filter1d(values, size=window)\n        smoothed[vid] = {i: smooth_values[j] for j, i in enumerate(indices)}\n    return smoothed\n\n\ndef create_submission(predictions, test_path):\n    data = []\n    for vid in sorted(predictions.keys()):\n        for frame in sorted(predictions[vid].keys()):\n            data.append({'Id': f\"{vid}_{frame}\", 'Predicted': predictions[vid][frame]})\n    return pd.DataFrame(data)\n\nprint(\"Prediction functions defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T14:54:34.593479Z","iopub.execute_input":"2025-12-29T14:54:34.593711Z","iopub.status.idle":"2025-12-29T14:54:34.608640Z","shell.execute_reply.started":"2025-12-29T14:54:34.593683Z","shell.execute_reply":"2025-12-29T14:54:34.607937Z"}},"outputs":[{"name":"stdout","text":"Prediction functions defined!\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"---\n## Cell 12: Run Predictions","metadata":{}},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*60)\nprint(\"STEP 4: RUNNING PREDICTIONS\")\nprint(\"=\"*60)\n\nraw_predictions = {}\n\nvideo_folders = sorted([f for f in os.listdir(FLIP_CLEANED_PATH) \n                        if os.path.isdir(os.path.join(FLIP_CLEANED_PATH, f))])\n\nfor folder in tqdm(video_folders, desc='Predicting'):\n    video_id = int(folder)\n    video_path = os.path.join(FLIP_CLEANED_PATH, folder)\n    raw_predictions[video_id] = predict_video(model, video_path, TEMPORAL_LENGTH, IMG_SIZE, COLOR_MODE, device)\n\nprint(f\"Predictions done for {len(raw_predictions)} videos\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T14:54:34.609465Z","iopub.execute_input":"2025-12-29T14:54:34.609744Z","iopub.status.idle":"2025-12-29T15:04:12.572604Z","shell.execute_reply.started":"2025-12-29T14:54:34.609722Z","shell.execute_reply":"2025-12-29T15:04:12.572004Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nSTEP 4: RUNNING PREDICTIONS\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Predicting: 100%|██████████| 21/21 [09:37<00:00, 27.52s/it]","output_type":"stream"},{"name":"stdout","text":"Predictions done for 21 videos\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"---\n## Cell 13: Normalize, Smooth & Save Submissions","metadata":{}},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*60)\nprint(\"STEP 5: CREATING SUBMISSIONS\")\nprint(\"=\"*60)\n\n# Normalize\nnormalized_predictions = normalize_predictions_global(raw_predictions)\n\n# Smooth\nsmoothed_predictions = smooth_predictions(normalized_predictions, SMOOTHING_WINDOW)\n\n# Save both\nsubmission_raw = create_submission(normalized_predictions, FLIP_CLEANED_PATH)\nsubmission_raw.to_csv('submission_raw.csv', index=False)\n\nsubmission_smooth = create_submission(smoothed_predictions, FLIP_CLEANED_PATH)\nsubmission_smooth.to_csv(SUBMISSION_FILE, index=False)\n\nprint(f\"Saved: submission_raw.csv\")\nprint(f\"Saved: {SUBMISSION_FILE} (smoothed)\")\nprint(f\"\\nTotal predictions: {len(submission_smooth)}\")\nprint(\"\\nSample predictions:\")\nprint(submission_smooth.head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T15:05:15.828097Z","iopub.execute_input":"2025-12-29T15:05:15.828662Z","iopub.status.idle":"2025-12-29T15:05:16.060768Z","shell.execute_reply.started":"2025-12-29T15:05:15.828631Z","shell.execute_reply":"2025-12-29T15:05:16.059771Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nSTEP 5: CREATING SUBMISSIONS\n============================================================\nSaved: submission_raw.csv\nSaved: submission.csv (smoothed)\n\nTotal predictions: 11706\n\nSample predictions:\n      Id  Predicted\n0  1_939   0.736914\n1  1_940   0.732922\n2  1_941   0.726875\n3  1_942   0.720741\n4  1_943   0.712068\n5  1_944   0.705770\n6  1_945   0.707159\n7  1_946   0.713317\n8  1_947   0.719394\n9  1_948   0.719754\n","output_type":"stream"}],"execution_count":20}]}